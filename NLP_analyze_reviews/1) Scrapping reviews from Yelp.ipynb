{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#First-steps\" data-toc-modified-id=\"First-steps-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>First steps</a></span></li><li><span><a href=\"#Web-Scraping-functions\" data-toc-modified-id=\"Web-Scraping-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Web Scraping functions</a></span></li><li><span><a href=\"#Running-Scraping\" data-toc-modified-id=\"Running-Scraping-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Running Scraping</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Yelp with Beautiful Soup\n",
    "We will scrape top restaurants reviews in New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c900e26f50244560a7ca3ab8b2f13939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method tqdm.pandas of <class 'tqdm._tqdm_notebook.tqdm_notebook'>>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps\n",
    "Creating a BeautifulSoup object with the webpage we want, here it's the default page when we specify restaurants in New York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = rq.get('https://www.yelp.com/search?find_desc=Restaurants&find_loc=New+York,+NY,+%C3%89tats-Unis').text\n",
    "soup = BeautifulSoup(html,\"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty DataFrame that will store all of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get Name and Address of each restaurants, and call the get_reviews() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_restaurants(restaurants, entries):\n",
    "    \n",
    "    new_restaurants1 = pd.DataFrame()\n",
    "    for s,i in tqdm(zip(entries,range(len(entries)))):\n",
    "        try:      \n",
    "            link = s.find('a', attrs={'class':'biz-name js-analytics-click'})['href']\n",
    "            reviews = get_reviews(link)\n",
    "            for t in range(reviews.shape[0]):\n",
    "                reviews.loc[t,'name']=s.find('a',attrs={'class':'biz-name'}).get_text().strip()\n",
    "                reviews.loc[t,'adress']=s.find('address').contents[0].strip()\n",
    "            new_restaurants1 = pd.concat([new_restaurants1,reviews],ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    restaurants = pd.concat([restaurants,new_restaurants1],ignore_index=True)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    return restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get the reviews from a restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(link):\n",
    "    \n",
    "    text = []\n",
    "    stars= []\n",
    "    html_link = rq.get('https://www.yelp.com'+link).text\n",
    "    soup_link = BeautifulSoup(html_link,\"lxml\")\n",
    "    \n",
    "    number_of_pages = soup_link.find('div', attrs={'class':'page-of-pages arrange_unit arrange_unit--fill'}).get_text().strip()\n",
    "    number_of_pages = int(number_of_pages.split('of ')[1])\n",
    "    \n",
    "    if(number_of_pages<2):#get the restaurants with a min of 20 reviews\n",
    "        return None\n",
    "    if(number_of_pages>7): #limit the number of reviews to 140\n",
    "        number_of_pages = 7\n",
    "\n",
    "    for i in range(number_of_pages):\n",
    "        reviews_list = soup_link.find('ul', attrs={'class':'ylist ylist-bordered reviews'})\n",
    "        for s,n in zip(reviews_list,range(len(reviews_list))):\n",
    "            try:\n",
    "                large_star = s.find('div',attrs={'biz-rating biz-rating-large clearfix'})\n",
    "                stars.append(large_star.find('img')['alt'][:3])\n",
    "                text.append(s.find('p').get_text(strip=True, separator=' '))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if (i!=number_of_pages-1):\n",
    "            link = soup_link.find('a', attrs={'u-decoration-none next pagination-links_anchor'})['href']\n",
    "            html_link = rq.get(link).text\n",
    "            soup_link = BeautifulSoup(html_link,\"lxml\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "    reviews = pd.DataFrame({'review':text,'stars':stars})\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "entries = soup.find_all('div',attrs={'class':'search-result'})\n",
    "restaurants = fill_restaurants(restaurants, entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then looping through the pages (there are 33 pages for New York because page 34 doesn't work).\n",
    "\n",
    "Yelp have blocked me after 1h30 hours (including previous cell) which retrieved me 13 000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [21:50, 42.27s/it]\n"
     ]
    }
   ],
   "source": [
    "number_of_pages = 1 #out of 33\n",
    "for i in range(number_of_pages):\n",
    "    next_page_link = soup.find('a',attrs={'class':'u-decoration-none next pagination-links_anchor'})['href']\n",
    "    html = rq.get('https://www.yelp.com'+next_page_link).text\n",
    "    soup = BeautifulSoup(html,\"lxml\")\n",
    "    entries = soup.find_all('div',attrs={'class':'search-result'})\n",
    "    restaurants = fill_restaurants(restaurants,entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants.to_csv('restaurants_ny.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
